{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f189916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Electricity_202502232316.csv')\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'], utc=True) - pd.Timedelta(minutes=30)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eb7ad21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Timestamp  Sun_Angle  Sun_Angle_Trend  hour_sin  hour_cos  \\\n",
      "0 2022-11-23 23:00:00+00:00        0.0               -1  0.000000  1.000000   \n",
      "1 2022-11-24 00:00:00+00:00        0.0               -1  0.258819  0.965926   \n",
      "2 2022-11-24 01:00:00+00:00        0.0               -1  0.500000  0.866025   \n",
      "\n",
      "     wd_sin    wd_cos  \n",
      "0  0.433884 -0.900969  \n",
      "1  0.433884 -0.900969  \n",
      "2  0.433884 -0.900969  \n",
      "Index(['Timestamp', 'Sun_Angle', 'Sun_Angle_Trend', 'hour_sin', 'hour_cos',\n",
      "       'wd_sin', 'wd_cos'],\n",
      "      dtype='str')\n",
      "Timestamp          datetime64[us, UTC]\n",
      "Sun_Angle                      float64\n",
      "Sun_Angle_Trend                  int64\n",
      "hour_sin                       float64\n",
      "hour_cos                       float64\n",
      "wd_sin                         float64\n",
      "wd_cos                         float64\n",
      "dtype: object\n",
      "index name: None\n"
     ]
    }
   ],
   "source": [
    "from data_preparation import pepare_data, preparation_data_darts\n",
    "df = pepare_data(df)\n",
    "series_scaled, cov_scaled, sc_tgt, sc_cov = preparation_data_darts(df)\n",
    "train_size = 0.8\n",
    "\n",
    "train, val = series_scaled.split_after(train_size)\n",
    "train_cov, val_cov = cov_scaled.split_after(train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bc6d63",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c098886",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_LEN   = 48   # look-back window\n",
    "OUTPUT_LEN  = 24   # forecast horizon\n",
    "BATCH_SIZE  = 256\n",
    "EPOCHS      = 300\n",
    "LR          = 1e-3\n",
    "SEED        = 42   # reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b71a7706",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Support for PyTorch based likelihood models not available. To enable them, install \"darts[torch]\" or \"darts[all]\" (with pip); or \"u8darts-torch\" or \"u8darts-all\" (with conda).\n",
      "Support for Torch based models not available. To enable them, install \"darts[torch]\" or \"darts[all]\" (with pip); or \"u8darts-torch\" or \"u8darts-all\" (with conda).\n",
      "The StatsForecast module could not be imported. To enable support for the AutoARIMA, AutoETS and Croston models, please consider installing it.\n",
      "The `XGBoost` module could not be imported. To enable XGBoost support in Darts, follow the detailed instructions in the installation guide: https://github.com/unit8co/darts/blob/master/INSTALL.md\n",
      "The `XGBoost` module could not be imported. To enable XGBoost support in Darts, follow the detailed instructions in the installation guide: https://github.com/unit8co/darts/blob/master/INSTALL.md\n",
      "ImportError: The `(Py)Torch` module could not be imported. To enable (Py)Torch support in Darts, follow the detailed instructions in the installation guide: https://github.com/unit8co/darts/blob/master/INSTALL.md\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "The `(Py)Torch` module could not be imported. To enable (Py)Torch support in Darts, follow the detailed instructions in the installation guide: https://github.com/unit8co/darts/blob/master/INSTALL.md",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdarts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TiDEModel\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model =\u001b[43mTiDEModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_chunk_length\u001b[49m\u001b[43m   \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mINPUT_LEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# encoder length\u001b[39;49;00m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_chunk_length\u001b[49m\u001b[43m  \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mOUTPUT_LEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# forecast horizon\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m          \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# width of every FC layer\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_encoder_layers\u001b[49m\u001b[43m   \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_decoder_layers\u001b[49m\u001b[43m   \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m              \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# keep dropout kwarg\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m           \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m         \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mSEED\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpl_trainer_kwargs\u001b[49m\u001b[43m    \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m  \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/EnergySchedulerNuc/.venv/lib64/python3.14/site-packages/darts/utils/utils.py:87\u001b[39m, in \u001b[36mNotImportedModule.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     \u001b[43mraise_log\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;167;43;01mImportError\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merror_message\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/EnergySchedulerNuc/.venv/lib64/python3.14/site-packages/darts/logging.py:132\u001b[39m, in \u001b[36mraise_log\u001b[39m\u001b[34m(exception, logger)\u001b[39m\n\u001b[32m    129\u001b[39m message = \u001b[38;5;28mstr\u001b[39m(exception)\n\u001b[32m    130\u001b[39m logger.error(exception_type + \u001b[33m\"\u001b[39m\u001b[33m: \u001b[39m\u001b[33m\"\u001b[39m + message)\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[31mImportError\u001b[39m: The `(Py)Torch` module could not be imported. To enable (Py)Torch support in Darts, follow the detailed instructions in the installation guide: https://github.com/unit8co/darts/blob/master/INSTALL.md"
     ]
    }
   ],
   "source": [
    "from darts.models import TiDEModel\n",
    "model =TiDEModel(\n",
    "    input_chunk_length   = INPUT_LEN,        # encoder length\n",
    "    output_chunk_length  = OUTPUT_LEN,        # forecast horizon\n",
    "    hidden_size          = 256,       # width of every FC layer\n",
    "    num_encoder_layers   = 2,\n",
    "    num_decoder_layers   = 2,\n",
    "    dropout              = 0.0,       # keep dropout kwarg\n",
    "    batch_size           = BATCH_SIZE,\n",
    "    random_state         = SEED,\n",
    "    pl_trainer_kwargs    = dict(\n",
    "        max_epochs  = EPOCHS,\n",
    "        accelerator = \"cpu\",\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "706080f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "   | Name                  | Type             | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0  | criterion             | MSELoss          | 0      | train\n",
      "1  | train_criterion       | MSELoss          | 0      | train\n",
      "2  | val_criterion         | MSELoss          | 0      | train\n",
      "3  | train_metrics         | MetricCollection | 0      | train\n",
      "4  | val_metrics           | MetricCollection | 0      | train\n",
      "5  | past_cov_projection   | _ResidualBlock   | 2.8 K  | train\n",
      "6  | future_cov_projection | _ResidualBlock   | 2.8 K  | train\n",
      "7  | encoders              | Sequential       | 534 K  | train\n",
      "8  | decoders              | Sequential       | 460 K  | train\n",
      "9  | temporal_decoder      | _ResidualBlock   | 726    | train\n",
      "10 | lookback_skip         | Linear           | 1.2 K  | train\n",
      "--------------------------------------------------------------------\n",
      "1.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 M     Total params\n",
      "4.009     Total estimated model params size (MB)\n",
      "57        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gerbrand/PycharmProjects/TideEnergy/.venv/lib64/python3.12/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 61/61 [00:04<00:00, 12.34it/s, train_loss=806.0, val_loss=3.63e+4]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 61/61 [00:04<00:00, 12.30it/s, train_loss=806.0, val_loss=3.63e+4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s]\n",
      "126.80661\n"
     ]
    }
   ],
   "source": [
    "from darts.metrics import mae\n",
    "from darts import TimeSeries\n",
    "import numpy as np\n",
    "\n",
    "model.fit(  series               = train,   # optional but helps\n",
    "future_covariates    = train_cov, # <- **required**\n",
    "val_series           = val,\n",
    "val_future_covariates= val_cov,\n",
    "past_covariates= train_cov,\n",
    "val_past_covariates= val_cov)\n",
    "  \n",
    "\n",
    "\n",
    "    # ❻  multi-step forecast matching the full validation span\n",
    "pred = model.predict(n=len(val)-INPUT_LEN,series= train, past_covariates= TimeSeries.concatenate(train_cov, val_cov),future_covariates=  TimeSeries.concatenate(train_cov, val_cov))\n",
    "\n",
    "    # ❼  inverse-transform back to original scale\n",
    "#pred = sc_tgt.inverse_transform(pred)\n",
    "#truth = sc_tgt.inverse_transform(val)\n",
    "    \n",
    "score_df =mae(val, pred)\n",
    "print(score_df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a03ab6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to /home/gerbrand/PycharmProjects/models/tide_model ✔\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Recommended by Darts: use model.save / model.load for full model serialization\n",
    "MODEL_PATH = '/home/gerbrand/PycharmProjects/models/tide_model'\n",
    "\n",
    "# Guard: ensure parent exists and remove previous saved model if present\n",
    "os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    shutil.rmtree(MODEL_PATH)\n",
    "\n",
    "model.save(MODEL_PATH)\n",
    "print(f'Model saved to {MODEL_PATH} ✔')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5019c813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(48, 1), (48, 6), (48, 6), (24, 6), None, (24, 1)]\n"
     ]
    }
   ],
   "source": [
    "ds = model.model.train_sample_shape    # still alive\n",
    "print(ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
